<h1>Esame del 25 Giugno 2024</h1>
<!-- 
<ol style="list-style-type: upper-alpha">
<li>the letter A</li>
<li>the letter B</li>
<li>etc</li>
</ol>

<style type="text/css">
   /* Indent Formatting */
   /* Format: a-1-i-A-1-I */
   ol {list-style-type: lower-alpha;}
   ol ol { list-style-type: decimal;}
   ol ol ol { list-style-type: lower-roman;}
   ol ol ol ol { list-style-type: upper-alpha;}
   ol ol ol ol ol { list-style-type: decimal;}
   ol ol ol ol ol ol { list-style-type: upper-roman;}
   /* https://www.w3schools.com/cssref/pr_list-style-type.asp */
   /* https://stackoverflow.com/questions/11445453/css-set-li-indent */
   /* https://stackoverflow.com/questions/13366820/how-do-you-make-lettered-lists-using-markdown */
</style> 
-->
<ol>
<li>Nel contesto della gestione della memoria virtuale, considera un sistema con demand paging. [cite: 5]
Rispondi alle seguenti domande:</li>
<ol style="list-style-type: upper-alpha">
<li><b>D</b> - La politica di sostituzione delle pagine del working set è una politica a dimensione fissa? (SI/NO) Spiega/motiva brevemente(<br>
<b>R</b> - No. La dimensione del resident set (ovvero il working set) cambia a seconda dell'insieme di pagine incluse nella finestra Delta.
</li>
<li>
<b>Q</b> - Perché è difficile implementare la politica del working set? (scegli la risposta/e giusta/e, sono possibili più risposte)<br>
<ul>
<li>Perché è difficile indovinare un buon tempo delta.
<b>R</b> - No. Il valore di delta influisce solo sulle performance, non sulla fattibilità della policy;
</li>
<li>Perché il resident set dovrebbe essere aggiornato anche in caso di assenza di PF.
<b>R</b> - Sì. In ogni momento il sistema deve monitorare costantemente quali pagine vengono accedute, rimuovere dal resident set le pagine che non sono state accedute per un tempo superiore a Δ, ecc. ;
</li>
<li>Perché la tecnica deve tenere traccia dell'ultimo tempo di accesso per ogni pagina.
<b>R</b> - Sì, come detto nella risposta precedente, le pagine il cui ultimo accesso è superiore a t-Δ devono essere rimosse;
</li>
<li>Perché la tecnica richiede di mantenere una lista dei tempi di accesso per ogni pagina.
<br>R</b> - No. La lista completa dei tempi di accesso sarebbe ridondante, basta il tempo dell'ultimo accesso.
</li>
</ul>
</li><!-- fine di B -->
<li><b>Q</b> - Considera una strategia LRU basata su un'implementazione a stack (con 5 frame). Data la seguente stringa di riferimento:<br>
4, 6, 4, 1, 7, 8, 2, 2, 3 (T1), 4, 2 (T2).
<br>Mostra lo stack (la lista) al tempo T1 (dopo aver acceduto alla pagina 3) e T2 (dopo aver acceduto alla pagina 2).
(rappresenta lo stack con numeri separati da virgole, con la cima dello stack per prima (es. 1,2,3,4,5 significa che 1 è la cima dello stack)) 
<br><b>R</b> - LRU - Least Recently Used - rimuoveremo la pagina usata da più tempo dopo il 5° frame<br>
Quindi dallo stack vuoto avremo: - 4, inserimento - 6, inserimento in cima, - 4, spostato in cima, - 1, inserimento in cima, - 7, inserimento in cima, - 8, inserimento in cima,
- 2, inserimento in cima e rimozione del 6, - 2 rimane in cima, -3 inserimento in cima e rimozione di 4<br>
a <b>T1</b> avremo <b>[3,2,8,7,1]</b><br>
- 4, inserimento in cima ed esce 1 - 2, passa in cima<br>
a <b>T2</b> avremo <b>[2,4,3,8,7]</b>
</li>
<li><b>D</b> - Considera due stringhe di riferimento w1 e w2 con la stessa lunghezza.
Sappiamo che $p2=2*p1$ (probabilità delle stringhe). Due algoritmi di sostituzione di pagina A1 e A2 sono valutati 
<i>usando lo stesso valore di m (fisso)</i>. A1 produce lo stesso numero di page fault ($F1=F2=5000$) con w1 e w2. 
Nel caso di A2, F1 e F2 cambiano, ma la loro somma rimane invariata. Poiché la frequenza di PF con A1 è del 20% peggiore
di A2, A2 viene infine selezionato. Calcola i valori di F1 e F2 misurati con l'algoritmo A2.<br>
(m è omesso nelle formule in quanto costante/invariato in tutti gli esperimenti).
<b>R</b> - Dati: 
<ul>
<li>F(Ai): frequenza media di page fault per l'algoritmo Ai;</li>
<li>F1(Ai,w1), F2(Ai,w2): page fault dell'algoritmo Ai sulle stringhe w1 e w2</li>
<li>Probabilità: p₁ = 1/3, p₂ = 2/3 (da p₂ = 2×p₁ e p₁ + p₂ = 1)</li></ul> 
F(Ai) = p₁×F₁(Ai,w1) + p₂×F₂(Ai,w2)
F1 e F2 sono date per l'algoritmo 1 (A1). Useremo le variabili x e y per F1 e F2 in A2.
Noi sappiamo che F(A1)/F(A2) = 1.2 -> x + y = 10000 <br>
F(A1)/F(A2) = p1*(5000+2*5000) / p1*(x+2y) = 1.2 <br>
1.2*(x+2y) = 15000 <br>
x+2y = 12500 <br>
utilizzando la seconda equazione (x+y = 10000) porta a x=7500, y=2500
</li>
</ol>
<li>Consideriamo un file system basato su allocazione indicizzata in cui, per gestire file di grandi dimensioni, i blocchi 
di indice sono organizzati in una lista collegata. I puntatori/indici hanno una dimensione di 32 bit e i blocchi disco hanno una dimensione di 4KB. 
Il file system risiede su una partizione disco da 1TB, che include sia blocchi di dati che blocchi di indice.
<ol style="list-style-type: upper-alpha">
<li><b>D</b> - Dato un file binario di dimensioni 23033 KB, calcola esattamente quanti blocchi di indice e blocchi di dati occupa il file.<br>
Calcola anche la frammentazione interna, sia per i blocchi di dati che per i blocchi di indice.<br>
<b>R</b> - Dati forniti:<br>
- Dim Puntatore/Indici : 32 bit -> 4 byte
- Dim blocchi : 4 KB
- Partizione fs : 1 TB
- file binario : 23033 KB <br>
Il numero di blocchi sarà dato dalla Dim File/ Dim Blocchi = 23033 * 10^3 / 4 * 10^3 = 5758,25 -> 5759<br>
Calcolo della capacità del blocco indice: Puntatori per blocco indice = Dimensione blocco / Dimensione puntatore = 4 KB / 4 B = 1024 -> 1K puntatori
ma puntatori dati per blocco = Puntatori per blocco indice -1 in quanto in un blocco indice c'è lo slot per il puntantore al blocco indice successivo -> 1023 puntatori <br>
Blocchi indice = Blocchi dati / puntatori dati per blocco = 5729 / 1023 = 5.6 -> 6 <br>
la frammentazione interna sarà data da (blocchi dati * dimensione blocco) - dim file -> frammentazione = Dim_blocco * (1- (Dim File % Dim Blocco)/ Dim Blocco) =<br>
 -> FI_dati = 4096 * (1 - ((23033 * 1024)%4096)/4096) = 4096 - 1024 = 3072 -> 3 KB <br>
 Per i blocchi indice invece avremo che la capacità totale sarà data da numero blocchi * puntatori utili = 6 blocchi * 1023 puntatori utili = 6138 slot per puntatori ai dati
quelli effettivamente utilizzati saranno uno per ogni blocco dati = 5759 puntatori, quelli sprecati li ricaviamo dalla diferrenza
Puntatori sprecati = 6138 - 5759  = 379 slot inutilizzati => considerando che ogni slot occupa 4 B => <br>
=> la frammentazione interna degli indici sarà = 379 * 4 B = 1516 B
</li>
<li><b>D</b> - Un file di testo B, di dimensioni 15300 B, contiene una sequenza di righe a lunghezza variabile, ciascuna terminata da '\n'.
Sappiamo che la lunghezza media della riga è di 50 caratteri (escluso '\n') e la lunghezza massima della riga è di 100. 
Calcola il numero di righe nel file (nel caso in cui il numero vari tra un valore minimo e uno massimo, calcola l'intervallo). <br>
<b>R</b> - Ripetiamo i dati: <br>
- Dim Totale = 15300 B; Lunghezza media riga 50 + 1 (51 Bytes); Lunghezza Max 100 + 1 (101 Bytes); minima (per deduzione) >= 1B (solo '\n');
Numero righe medio = Dimensione file / lunghezza media riga = 15300 / 51 = 300 B (nessun altro calcolo necessario visto che ci chiede la media)
</li>
<li>Considera il file B (della domanda precedente). (Spiega/motiva entrambe le risposte) 
<ul>
<li><b>D</b> - Il formato di record a lunghezza variabile influisce sull'allocazione?<br>
<b>R</b> - No, a livello di fs vede solo una sequenza di byte da allocare, e la strategia dipenderà in base al fs.
</li>
<li><b>D</b> - Tutti i blocchi allocati memorizzano la stessa quantità di righe di file, data dalla dimensione di un blocco divisa per la lunghezza massima della riga?<br>
<b>R</b> - No. L'allocazione dei file è gestita a livello del modulo dell'allocazione dei file, mentre le linee del testo del file sono un problema a livello applicativo.
</li>
</ul>
</li>
</ol>
</li>
<li>Considera la gestione della memoria con paging e una MMU con TLB.Per ciascuna delle seguenti domande, rispondi SÌ o NO e fornisci una motivazione/spiegazione.:
<ol style="list-style-type: upper-alpha">
<li><b>D</b> - La reach della TLB diminuisce quando la dimensione della pagina aumenta?<br>
<b>R</b> - No, aumenta, in quanto il numero di record all'interno della TLB è costante.Per definizione, la reach della TLB è la quantità totale di memoria virtuale
che può essere indirizzata attraverso le entry presenti nella TLB. Quindi Reach_TLB = Numero_entry_TLB * Dimensione_pagina =>
Se aumenta la dimensione, aumenta la reach.
</li>
<li><b>D</b> - La frammentazione aumenta, quando la dimensione della pagina aumenta, perché sono necessarie partizioni contigue più grandi? <br>
<b>R</b> - No, la frammentazione interna aumenta effettivamente con l'aumentare della dimensione delle pagine, 
ma la ragione proposta è sbagliata. Nel paging non esiste allocazione contigua - le pagine virtuali possono essere 
mappate su frame fisici qualsiasi, quindi non sono necessarie "partizioni contigue più grandi". La frammentazione interna 
aumenta perché lo spreco medio nell'ultima pagina è maggiore;
</li>
<li>
<b>D</b> - Il prepaging è utile solo se la probabilità che una pagina prepaginata venga effettivamente utilizzata è > 80%? <br>
<b>R</b> - No, è utile comunque, basta una probabilità significativamente alta (solitamente al di sopra del 50%).
Una soglia dell'80% è troppo restrittiva e non ha basi teoriche solide.
</li>
<li>
<b>D</b> - Tutte le strutture dati del kernel richiedono allocazione contigua?
<b>R</b> - No, solo le perti del kernel le cui strutture dati hanno bisogno di allocazione continua (per efficienza):
ad esempio 1. Buffer I/O e DMA;2. Strutture hardware-sensitive (i.e. la tabella delle pagine) 3. 
Strutture piccole e performance-critical (i.e. Process control blocks (PCB))
</li>
<li>
<b>D</b> - L'allocatore slab utilizza solo dimensioni potenza di 2? 
<b>R</b> - No, è il sistema buddy che comporta un allocatore a potenze di 2;
</li>
<li>
<b>D</b> - Una free list di pagine ha una frammentazione interna media di mezza pagina?
<b>R</b> - No, essendo una lista di pagine libere non ha problemi di frammentazione interna in quanto non contiene dati, ma rappresentano
lo spazio disponibile
</li>
</ol>
</li>
</ol>


**Domanda 4** [cite: 42]
È dato un sistema OS161, in esecuzione su un simulatore sys161 MIPS con 4MB di memoria RAM. [cite: 42] Per ciascuno dei seguenti indirizzi, indica se può essere un indirizzo logico utente, un indirizzo logico kernel, un indirizzo fisico (spiega/motiva le risposte): [cite: 43]

$0x80803005$:

$0x312010$:

$0x532100$:

Dato un indirizzo logico utente $0x4010$, convertilo nel relativo indirizzo fisico. [cite: 46] È noto che as->as\_pbase1, as->as\_pbase2, as->as\_vbase1, as->as\_vbase2, as->as\_npages1, as->as\_npages2 hanno i seguenti valori: [cite: 46]
$0x100000, 0x200000, 0x3000, 0x6000, 2, 4$. [cite: 46]

La memoria fisica in dumbvm è allocata per multipli di una pagina, nonostante sia uno schema di allocazione contigua, perché:

* l'allocazione per multipli di una pagina riduce la frammentazione interna
* la MMU in MIPS ha una TLB, quindi la traduzione da logico a fisico richiede pagine
* dumbvm implementa una tabella delle pagine
* kmalloc può allocare solo per multipli di pagine.

**Domanda 5** [cite: 49]
Considera l'implementazione di lock e variabili di condizione in OS161. Per ciascuna delle seguenti frasi, rispondi SÌ/NO e fornisci una motivazione: [cite: 49]

La funzione `cv_wait` riceve un lock come parametro perché:

* è necessario come parametro nella chiamata interna a `wchan_sleep` [cite: 49]
* il thread chiamante deve essere il proprietario del lock [cite: 49]
* il lock deve essere rilasciato e acquisito di nuovo da `cv_wait` [cite: 49]
* il lock deve essere rilasciato e acquisito di nuovo da `wchan_sleep` [cite: 50]

Il lock può essere implementato:

* da un semaforo binario, senza nessun altro elemento/requisito [cite: 50]
* da un semaforo binario, più un elemento/requisito aggiuntivo [cite: 51]
* da una variabile di condizione [cite: 52]
* da un canale di attesa [cite: 53]

L'implementazione della funzione `lock_acquire` può includere una chiamata a:

* le funzioni `spinlock_data_get` e `spinlock_data_testandset` [cite: 54]
* la funzione P su un semaforo [cite: 55]
* la funzione `cv_wait` [cite: 56]
* la funzione `wchan_sleep` [cite: 56]